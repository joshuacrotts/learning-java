\section{Recursion}

In this section we reintroduce recursion as a means of problem decomposition and repetition. 
We present two forms: standard recursion and tail recursion, as well as the issues that come with both forms in Java. 
The discussion starts with a review of basic arithmetic and its relation to recursion.

\subsection{Standard Recursion}
You may or may not have seen recursion before, but in theory the concept is quite simple: a method~$f$ is \emph{recursive} if, somewhere in the definition of \emph{f}, it invokes itself. 
For example, in the following code segment, we define~$f$ to be a method of arbitrary arguments that calls itself from its body. 

\begin{verbnobox}[\small]
static int f(...) {
  ...
  f(...);
  ...
}
\end{verbnobox}

Some may question the need for recursive methods, as it appears to be circular; why would we ever want a method to call itself? 
There are two reasons, where the former is what we consider to be a less significant reason than the latter:

\begin{enumerate}
    \item It allows the programmer to repeat a given segment of code.
    \item We can compose the solution to a big problem by combining the solutions to smaller problems.
\end{enumerate}

So, we may certainly use recursion to repeat a task, but we primarily design recursive methods to solve large problems by breaking them down into small, simple problems that we know how to solve.

\myexample{Let's consider the question of addition.} 
Consider a context where we have access to only three methods: \ttt{addOne}, \ttt{subOne}, and \ttt{isZero}, all of which are trivially defined. 
We also have access to conditional statements and method calls. 
Finally, we have an identity that~$m + 0 = m$ for any natural number~$m$. 
Here's the problem that we want to solve: we want to add two natural numbers~$m$ and~$n$, but how do we do that? 
Think about how humans calculate the sum of two natural numbers (perhaps some do it differently from others, but the general process is the same). 
Since we do not have a \ttt{+} operator in this context, we have to try a different approach. 
Recall the identity that we have at our disposal: $m + 0 = m$. 
Is there a way we can make use of the identity? 
Imagine that we want to solve~$3 + 4$ in this context. 
Can we rewrite this expression that takes advantage of those methods that we have at our disposal? 
Indeed, we can rewrite $3+4$ as a series of calls to \ttt{subOne} and \ttt{addOne}, but we will first show this idea in math notation.

\begin{align*}
    &= 3 + 4\\
    &= (3 + 3) + 1\\
    &= ((3 + 2) + 1) + 1)\\
    &= (((3 + 1) + 1) + 1) + 1\\
    &= ((((3 + 0) + 1) + 1) + 1) + 1
\end{align*}

To solve $3 + 4$, we need to solve $3 + 3$, which means we need to solve $3 + 2$, which means we need to solve $3 + 1$, which means we need to solve $3 + 0$. 
Substituting~$3$ for~$m$ produces the identity, meaning this expression resolves to~$m$, namely~$3$. 
Recursively breaking down a problem into smaller problems is called \emph{invoking the recursion}. 
Namely, we invoke the method of interest, \ttt{+}, inside its own definition. 
As part of this, we decrement~$n$ by one in attempt to head towards the identity, or the problem that \emph{we know} how to solve. 
Such a problem is called the \emph{base case} to a recursive method. 
How do we know when and where to analyze~$m$ as a base case? 
We know that~$m$ is the base case when~$n$ is zero because of the known identity.

We still have work to do after reaching the base case, however. 
Even though we may substitute $3+0$ for $3$, we have to add one to these resulting values. Let's examine this.

\begin{align*}
    &= ((((3 + 0) + 1) + 1) + 1) + 1\\
    &= (((3 + 1) + 1) + 1) + 1\\
    &= ((4 + 1) + 1) + 1\\
    &= (5 + 1) + 1\\
    &= 6 + 1\\
    &= 7
\end{align*}

Upon reaching the base case, using the pieces generated by the recursion, we create the solution to our overall problem. 
In other words, to solve $3 + 1$, we had to solve $3 + 0$, whose base case resolves to~$3$. 
We subsequently walk back up through the series of recursive calls, filling in the gaps to previously-unknown solutions. 
Because $3 + 0 = 3$, we know the answer to $3 + 1$. 
The substitution continuously propagates back through the recursive calls, and we arrive at our desired solution of~$7$. 
Traversing through the recursive calls backwards, while building the solution to the overall problem, is called \emph{unwinding the recursion}. 
Now that we understand the logic of our problem, let's design the method in Java. 
First, of course, we want to design our tests.

\enlargethispage{-5\baselineskip}
\begin{lstlisting}[language=MyJava]
import static Assertions.assertAll;
import static Assertions.assertEquals;

class AddTester {
  
  @Test
  void testAdd() {
    assertAll(
      () -> assertEquals(7, add(3, 4)),
      () -> assertEquals(12, add(11, 1)),
      () -> assertEquals(6, add(0, 6)),
      () -> assertEquals(6, add(6, 0)));
  }
}
\end{lstlisting}

\begin{lstlisting}[language=MyJava]
class Add {

  /**
   * Adds two natural numbers. Uses recursion and the addOne, 
   * subOne, and isZero methods.
   * @param m the first number.
   * @param n the second number.
   * @return the sum.
   */
  static int add(int m, int n) {
    if (isZero(n)) { 
      return m;
    } else {
      return addOne(add(m, subOne(n)));
    }
  }
}
\end{lstlisting}

Our recursive implementation is nothing more than a restatement of the mathematical definition, which is convenient. 
Let's trace through a sequence of recursive calls from invoking \ttt{add(3, 4)}.

\begin{align*}
    \text{Is }\ttt{4} \text{ zero?} &\text{ No! }\ttt{return addOne(add(3, 3))}\\
    \text{Is }\ttt{3} \text{ zero?} &\text{ No! }\ttt{return addOne(add(3, 2))}\\
    \text{Is }\ttt{2} \text{ zero?} &\text{ No! }\ttt{return addOne(add(3, 1))}\\
    \text{Is }\ttt{1} \text{ zero?} &\text{ No! }\ttt{return addOne(add(3, 0))}\\
    \text{Is }\ttt{0} \text{ zero?} &\text{ Yes! }\ttt{return 3.}
\end{align*}

Once we reach the base case, we unwind the recursive calls, substituting our known values for their previously-unknown values.

\begin{align*}
    \text{We now know }\ttt{add(3, 0)} \text{ is }\ttt{3}\text{. So, } &\ttt{return addOne(add(3, 0))} \text{ is } \ttt{return 4}\\
    \text{We now know }\ttt{add(3, 1)} \text{ is }\ttt{4}\text{. So, } &\ttt{return addOne(add(3, 1))} \text{ is } \ttt{return 5}\\
    \text{We now know }\ttt{add(3, 2)} \text{ is }\ttt{3}\text{. So, } &\ttt{return addOne(add(3, 2))} \text{ is } \ttt{return 6}\\
    \text{We now know }\ttt{add(3, 3)} \text{ is }\ttt{3}\text{. So, } &\ttt{return addOne(add(3, 3))} \text{ is } \ttt{return 7}\\
    \text{We now know }\ttt{add(3, 4)} \text{ is }\ttt{7}\text{. So, } &\text{we are done.} 
\end{align*}

Recursion, as we stated before, composes the solution to a large problem by first solving smaller ``easier'' problems.

\myexample{Consider the factorial mathematical operation.}
The factorial of a natural number~$n$ obeys the following definition:

\begin{align*}
    0! &= 1\\
    n! &= n \cdot (n - 1) \cdot (n - 2) \cdot \ldots \cdot 1
\end{align*}

Factorial is a naturally-recursive mathematical operation. 
To solve~$n!$, we need to solve $(n-1)!$, which means we need to solve $(n-2)!$, all the way down to our base case of $0!=1$. 
Rewriting the prior definition to use explicit recursion gets us the following: \

\begin{align*}
    0! &= 1\\
    n! &= n \cdot (n - 1)!
\end{align*}

Let's trace through a factorial invocation.

\begin{align*}
    5! &= 5 \cdot 4!\\
    4! &= 4 \cdot 3!\\
    3! &= 3 \cdot 2!\\
    2! &= 2 \cdot 1!\\
    1! &= 1 \cdot 0!
\end{align*}

So, after the recursive calls, we hit our base case. 
We still have work to do afterwards, much like how \ttt{add} unwinds its recursion. 
Rather than \ttt{addOne}, we extend our context to include multiplication for the sake of brevity, and use that as an operation. 
Therefore, when unwinding the recursive calls, we get the following trace:

\begin{align*}
0! &= 1\\
1! &= 1 \cdot 1\\
2! &= 2 \cdot 1\\
3! &= 3 \cdot 2\\
4! &= 4 \cdot 6\\
5! &= 5 \cdot 24\\
   &= 120
\end{align*}

Now let's design the \ttt{factorial} method in Java, again with tests taking immediate precedence over the method definition.

\enlargethispage{-5\baselineskip}
\begin{lstlisting}[language=MyJava]
import static Assertions.assertAll;
import static Assertions.assertEquals;

class FactorialTester {
  
  @Test
  void testFact() {
    assertAll(
      () -> assertEquals(120, fact(5)),
      () -> assertEquals(1, fact(0)),
      () -> assertEquals(1, fact(1)),
      () -> assertEquals(3628800, fact(10)));
  }
}
\end{lstlisting}
\begin{lstlisting}[language=MyJava]
class Factorial {

  /**
   * Computes the factorial of a number.
   * @param n the number to compute the factorial of.
   * @return factorial result.
   */
  static int fact(int n) {
    if (isZero(n)) {
      return 1;
    } else {
      return n * fact(subOne(n));
    }
  }
}
\end{lstlisting}

Once more will we derive a trace, but this time of the \ttt{fact} method when invoked with~$5$.

\begin{align*}
    \text{Is }\ttt{5} \text{ zero?} &\text{ No! }\ttt{return 5 * fact(4)}\\
    \text{Is }\ttt{4} \text{ zero?} &\text{ No! }\ttt{return 4 * fact(3)}\\
    \text{Is }\ttt{3} \text{ zero?} &\text{ No! }\ttt{return 3 * fact(2)}\\
    \text{Is }\ttt{2} \text{ zero?} &\text{ No! }\ttt{return 2 * fact(1)}\\
    \text{Is }\ttt{1} \text{ zero?} &\text{ No! }\ttt{return 1 * fact(0)}\\
    \text{Is }\ttt{0} \text{ zero?} &\text{ Yes! }\ttt{return 1}
\end{align*}

Upon arriving at the base case, we begin to unwind the recursive calls.

\begin{align*}
    &\text{We now know }\ttt{fact(0)} \text{ is }\ttt{1}\text{. So, } \ttt{return 1 * 1} \text{ is } \ttt{return 1}\\
    &\text{We now know }\ttt{fact(1)} \text{ is }\ttt{2}\text{. So, } \ttt{return 2 * 1} \text{ is } \ttt{return 2}\\
    &\text{We now know }\ttt{fact(2)} \text{ is }\ttt{2}\text{. So, } \ttt{return 3 * 2} \text{ is } \ttt{return 6}\\
    &\text{We now know }\ttt{fact(3)} \text{ is }\ttt{6}\text{. So, } \ttt{return 4 * 6} \text{ is } \ttt{return 24}\\
    &\text{We now know }\ttt{fact(4)} \text{ is }\ttt{24}\text{. So, } \ttt{return 5 * 24} \text{ is } \ttt{return 120}\\
    &\text{We now know }\ttt{fact(5)} \text{ is }\ttt{120}\text{. So, } \text{we are done.} 
\end{align*}
Voil\`a, we get our desired solution.

\subsection{Tail Recursion and Accumulators}
In the previous section, we discussed recursion, or what we will refer to as \emph{standard recursion}\index{standard recursion}. 
This style of recursion is popular because of its ease-of-use and relative correlation to mathematical definitions. 
Unfortunately, there is a significant problem with standard recursion: it is a memory hog and potential recipe for disaster. 
The reason does not easily present itself to the programmer, and we have to dive deeper into how Java makes method calls to fully explain what goes awry.

Each time Java invokes a method, it pushes an \emph{activation record}\index{activation record}\index{stack frame} to its \emph{method call stack}\index{method call stack}. 
The call stack is a location in memory where all method invocations reside. 
Activation records contain information about the method that was called, such as its arguments, the locally-defined variables, and other miscellaneous data. 
More importantly, activation records designate the ``return location'' of a method. 
When a method call returns, it is popped off the top of the call stack. 
The call stack's memory, or lack thereof, is the root cause of problems with standard recursion. 
Let us demonstrate this predicament with an example trace of \ttt{add} whose second argument is incredibly large; over two million.

As we stated, calling a method pushes its activation record to the method call stack, so invoking \ttt{add(3, 2000000)} pushes one record. 
Then, because two million is certainly not zero, we then recursively call \ttt{add(3, 1999999)} and push that record to the call stack. 
This idea continues until we reach a point where there is not enough memory to push another activation record onto the (call) stack, in which a \ttt{StackOverflowError} is thrown by the Java Virtual Machine. 
We need a way of writing recursive algorithms without having to waste so much memory and risk a stack overflow of the call stack. 
A potential solution to our problem is via \emph{tail recursion}\index{tail recursion} through \emph{accumulator-passing style}\index{accumulator-passing style}.

\begin{figure}
\begin{center}
\begin{tikzpicture}[
  stack/.style={draw, minimum width=3cm, minimum height=0.2cm},
]

% Draw the stack frames
\node[stack] (frame1) {\ttt{add(3, 20000)}};
\node[stack, above=0.0cm of frame1] (frame2) {\ttt{add(3, 19999)}};
\node[stack, above=0.0cm of frame2] (frame3) {\ttt{add(3, 19998)}};
\node[stack, above=0.0cm of frame3] (frame4) {\ttt{add(3, 19997)}};
\node[stack, above=0.0cm of frame4] (frame5) {\ttt{add(3, 19996)}};
\node[stack, above=0.0cm of frame5] (frame6) {$\cdots$};
\node[stack, above=0.0cm of frame6] (frame7) {$\cdots$};
\node[stack, above=0.0cm of frame7] (frame8) {$\cdots$};
\node[stack, above=0.0cm of frame8] (frame9) {$\cdots$};
% \node[stack, above=0.0cm of frame9] (frame10) {$\cdots$};
% \node[stack, above=0.0cm of frame10] (frame11) {$\cdots$};
% \node[stack, above=0.0cm of frame11] (frame12) {$\cdots$};
% \node[stack, above=0.0cm of frame12] (frame13) {$\cdots$};
\end{tikzpicture}
\end{center}
\caption{Pushing of \ttt{add} Activation Records to the Call Stack}
\end{figure}

A method~$f$ is \emph{tail recursive}\index{tail recursive} if all recursive calls are in \emph{tail position}\index{tail position}. 
At first glance, this definition appears circular due to the similar terms used. 
But, consider this piece: an expression is in tail position if it is in the last-to-perform operation before a method returns. 
Both \ttt{add} and \ttt{fact} are non-tail recursive methods, because each have extra work to do; that work being an unwinding of the recursive calls. 
Tail recursive functions do not need to unwind anything because they (for the most part) accumulate the result to an overall problem in an argument to the tail recursive method.

\myexample{We want to compute the factorial of some number using tail recursion.} 
Let's design a template for such a method. 
We know that the method must be called where the call is in tail position, so we can add it as a preliminary step. 
Up next, we can copy the logic of the previous standard recursive algorithm with the added exception that we do not return one from the base case, but instead return an accumulated result. 
The goal is to construct, or generate, the factorial of some~$n$ as an argument to the method.

\begin{lstlisting}[language=MyJava]
class Factorial {

  /**
   * Tail recursive method for computing the factorial of a number.
   * @param n the number to compute the factorial of.
   * @param acc the accumulator for the result.
   * @return the factorial of the number.
   */
  static int factTR(int n, int acc) {
    if (isZero(n)) { return acc; } 
    else { return factTR(n - 1, acc * n); }
  }
}
\end{lstlisting}

Observe that the only change to the base case occurs in the body of the condition. 
So, the first argument to \ttt{factTR}, i.e., $n$, still trends towards the base case and, hence, should be the decrement of~$n$. 
Oppositely, \ttt{acc} stores an accumulated factorial result. 
We multiply the accumulator variable by~$n$ with every (tail) recursive call, meaning that the accumulator approaches the solution.

Let's perform a trace of \ttt{factTR} to see how we build the result in the \ttt{acc} parameter. 
One extra factor to consider is the initial/starting value of our accumulator argument. 
The starting value of a tail recursive method depends on the context of the problem, and for factorial, the only reasonable value is one. 
For example, if we initialize \ttt{acc} to zero, then we would continuously multiply and store zero as the argument to the recursive call and always return zero as the factorial of any number.

\begin{align*}
    \text{Is }\ttt{5} \text{ zero?} &\text{ No! }\ttt{return factTR(4, 5)}\\
    \text{Is }\ttt{4} \text{ zero?} &\text{ No! }\ttt{return factTR(3, 20)}\\
    \text{Is }\ttt{3} \text{ zero?} &\text{ No! }\ttt{return factTR(2, 60)}\\
    \text{Is }\ttt{2} \text{ zero?} &\text{ No! }\ttt{return factTR(1, 120)}\\
    \text{Is }\ttt{1} \text{ zero?} &\text{ No! }\ttt{return factTR(0, 120)}\\
    \text{Is }\ttt{0} \text{ zero?} &\text{ Yes! }\ttt{return 120}
\end{align*}

The base case simply returns the accumulated value from the method. 
We do not need to unwind the recursive calls, since there is no extra work to be done after making the recursive calls in the first place. 
Even still, some may question how this avoids a stack overflow error, because we still push an activation record to the call stack each time we invoke \ttt{factTR}, right? 
Indeed, this solution does not solve the stack overflow problem, because Java does not employ the necessary optimizations to do so.
What might one of those solutions be, in fact? As a hypothesis, because the method is tail recursive, the Java compiler could detect this and, instead of pushing a new activation record to the call stack, overwrite the preexisting record, hence using constant space and only one record. 
Overriding the existing activation record is permissible, since we do not unwind the stack.
Recall with standard recursion that we push an activation record to the call stack to remember the context of ``how deep we are'' into the recursion, in addition to what values we must substitute back into the unknowns during the unwinding phase. 
Conversely, when examining the tail recursive approach, we build the result alongside heading towards the base case, meaning previous recursive calls are irrelevant. 
Let's see what this looks like in the model of a stack.

\begin{figure}
\begin{center}
\begin{tikzpicture}[
  stack/.style={draw, minimum width=3cm, minimum height=0.6cm},
]

%5
\node[stack] (frame1) {\ttt{factTR(5, 1)}};
\node[stack, above=0.0cm of frame1] (frame2) {\ttt{$\cdots$}};
\node[stack, above=0.0cm of frame2] (frame3) {\ttt{$\cdots$}};

%4
\node[stack, right=1cm of frame1] (frame1b) {\ttt{factTR(4, 5)}};
\node[stack, above=0.0cm of frame1b] (frame2b) {\ttt{$\cdots$}};
\node[stack, above=0.0cm of frame2b] (frame3b) {\ttt{$\cdots$}};

%3
\node[stack, right=1cm of frame1b] (frame1c) {\ttt{factTR(3, 20)}};
\node[stack, above=0.0cm of frame1c] (frame2c) {\ttt{$\cdots$}};
\node[stack, above=0.0cm of frame2c] (frame3c) {\ttt{$\cdots$}};

%2
\node[stack, below=2cm of frame1] (frame1d) {\ttt{factTR(2, 60)}};
\node[stack, above=0.0cm of frame1d] (frame2d) {\ttt{$\cdots$}};
\node[stack, above=0.0cm of frame2d] (frame3d) {\ttt{$\cdots$}};

%1
\node[stack, right=1cm of frame1d] (frame1e) {\ttt{factTR(1, 120)}};
\node[stack, above=0.0cm of frame1e] (frame2e) {\ttt{$\cdots$}};
\node[stack, above=0.0cm of frame2e] (frame33) {\ttt{$\cdots$}};

%0
\node[stack, right=1cm of frame1e] (frame1f) {\ttt{factTR(0, 120)}};
\node[stack, above=0.0cm of frame1f] (frame2f) {\ttt{$\cdots$}};
\node[stack, above=0.0cm of frame2f] (frame3f) {\ttt{$\cdots$}};

% Arrow between the first and second stacks
\draw[->,thick] (frame1.east) -- (frame1b.west);
\draw[->,thick] (frame1b.east) -- (frame1c.west);
\draw[->, thick, rounded corners] 
    (frame1c.south) |- ($ (frame1c)!0.5!(frame3d) $)
                      -| (frame3d.north);
\draw[->,thick] (frame1d.east) -- (frame1e.west);
\draw[->,thick] (frame1e.east) -- (frame1f.west);

\end{tikzpicture}
\end{center}
\caption{Simulated Tail Recursion with ``Multiple Stacks''}
\end{figure}

The transitions between each ``stack'' represent the same stack wherein they represent a point in time. 
Following the invocation of \ttt{factTR(5, 1)}, we recursively call \ttt{factTR(4, 5)}, and replace the previous activation record. 
This follows suit until we hit the base case and return the accumulator.

Tail recursion often exposes its use of an accumulator to the caller of the method. 
The user of such a factorial function should not need to worry about what value to pass as the initial accumulator; they only want a method that computes the factorial of some natural number. 
The solution is to write a \emph{driver method}\index{driver method} and introduce \emph{method access modifiers}\index{method access modifiers}. 
Driver methods, in short, serve to ``jump start'' the logic for some other, perhaps more complex, method. 
We should refactor the logic from \ttt{factTR} into a helper method that is inaccessible from outside the class. 
To do so, we affix the \ttt{private} keyword in front of \ttt{static}. 
Private methods are unreachable/not callable from outside the class in which it is declared.

\begin{lstlisting}[language=MyJava]
class Factorial {
  
  /**
   * Tail recursive (driver) method for computing the factorial of a number.
   * @param n the number to compute the factorial of.
   * @return the factorial.
   */
  static int factTR(int n) {
    return factHelper(n, 1);
  }

  /**
   * Helper method to compute the factorial of a number using tail recursion.
   * @param n the number to compute the factorial of.
   * @param acc the accumulator for the result.
   * @return the factorial of the number.
   */
  private static int factHelper(int n, int acc) {
    if (isZero(n)) { return acc; } 
    else { return factHelper(subOne(n), acc * n); }
  }
}
\end{lstlisting}

Notice that we localized the tail recursive method to this class and updated the signature of \ttt{factTR} to only have one parameter. 
We designate \ttt{factTR} as the driver method for jump-starting the tail recursion that occurs in \ttt{factHelper}. 
Driver methods should share the same signature with their standard recursion method counterparts so as to not expose the innard implementation of a method to the caller. 
Hiding method implementation in this fashion is called \emph{encapsulation}\index{encapsulation}. 

\myexample{Let us get a bit more practice with recursion by integrating strings into the mixture.} 
Suppose that we want to design a method that removes all characters whose position is a multiple of three. 
For example, given the string \ttt{"ABCDEFGHI"}, we want to return \ttt{"ABDEGH"}, since \ttt{"C"}, \ttt{"F"}, and \ttt{"I"} are located at positions (note the use of position and not index) are divisible by three. 
Tests are, of course, warranted and necessary.

\begin{lstlisting}[language=MyJava]
import static Assertions.assertAll;
import static Assertions.assertEquals;

class RemoveDivThreeCharsTester {

  @Test
  void testRemoveDivThreeChars() {
    assertAll(
      () -> assertEquals("ABDEGH", removeDivThreeChars("ABCDEFGHI")),
      () -> assertEquals("CCC", removeDivThreeChars("CC")),
      () -> assertEquals("AB", removeDivThreeChars("AB")),
      () -> assertEquals("A", removeDivThreeChars("A")),
      () -> assertEquals("", removeDivThreeChars("")),
      () -> assertEquals("ABCD", removeDivThreeChars("ABD")));
  }
}
\end{lstlisting}

We break our input down into two cases: when the string does not have at least three characters, and otherwise. 
If the string has less than three characters, we return the string itself. 
If the string has at least three characters, we compose a new string containing the first two characters, skipping the third, and recursing on the rest. 
In the \ttt{else} case, we are guaranteed that the input string has at least three characters, implying that \ttt{substring(3)} can never fail. 
Because the \ttt{substring} method of one argument is exclusive, if the provided index is the end of the string, the empty string is returned.

\begin{lstlisting}[language=MyJava]
class RemoveDivThreeChars {

  /**
   * Removes characters at positions divisible by three.
   * @param s the given string.
   * @return the resulting string.
   */
  static String removeDivThreeChars(String s) {
    if (s.length() < 3) {
      return s;
    } else {
      return s.substring(0, 2) + removeDivThreeChars(s.substring(3));
    }
  }
}
\end{lstlisting}

Thinking recursively takes time, and there is no better way to get better than extensive practice. Let's now convert the method into its tail recursive counterpart. 
Due to the trivial nature of writing tests, we omit them for our tail recursive version. 
The algorithm remains largely the same, except for the added accumulator, which builds the resulting string rather than relying on the recursive unwinding to compose the solution. 
Our base case concatenates~$s$ onto the end of the accumulator.

%\enlargethispage{5\baselineskip}
\begin{lstlisting}[language=MyJava]
class RemoveDivThreeChars {

  /**
   * Tail recursive (driver) method to remove characters at 
   * positions divisible by three.
   * @param s the given string.
   * @return the resulting string.
   */
  static String removeDivThreeCharsTR(String s) {
    return removeDivThreeCharsTRHelper(s, "");
  }

  /**
   * Helper method to remove characters at positions 
   * divisible by three using tail recursion.
   * @param s the given string.
   * @param acc the accumulator for the result.
   * @return the resulting string.
   */
  private static String removeDivThreeCharsTRHelper(String s, String acc) {
    if (s.length() < 3) {
      return acc + s;
    } else {
      return removeDivThreeCharsTRHelper(s.substring(3), acc+s.substring(0, 2));
    }
  }
}
\end{lstlisting}

\myexample{Let's design a recursive method to remove sequences of duplicate characters.}
For example, consider \ttt{"aaabbcdddc"}.
Removing sequential characters from this string produces \ttt{"abcdc"}.

Let's think about the base case and recursive step for the algorithm.
One base case we can derive is when the string contains at most one character, meaning we return that string.
On the other hand, the string must contain at least two characters that may be identical. 
At first, we may think to check whether the first and second characters and, if so, recurse without the second character and prepend the first. 
Sadly, this only removes every other duplicate character.
We need to keep track of what character we are removing from the string in a sequence.
If we are removing \ttt{\q{}a\q{}} from the above example, we want to concatenate \ttt{\q{}a\q{}} onto the front of the recursive call, then recurse on the rest of the string, but pass \ttt{\q{}a\q{}} as a parameter.
Until we reach a non-\ttt{\q{}a\q{}} character, we simply recurse on the rest of the string without concatenating a character.
Notice that the initial call to the helper method, namely \ttt{remSeqCharsHelper}, contains the null character literal, i.e., \ttt{\q{}\textbackslash{}0\q{}}. 
% If readers prefer, they can instead make use of one-character strings instead of characters and pass \ttt{null} (or even the empty string).

\enlargethispage{3\baselineskip}
\begin{lstlisting}[language=MyJava]
class RemoveSequentialCharsTester {

  @Test
  void testRemoveSequentialChars() {
    assertAll(
      () -> assertEquals("abcdc", remSeqChars("aaaabbcdddc")),
      () -> assertEquals("abcde", remSeqChars("abcde")),
      () -> assertEquals("aaaaa", remSeqChars("")),
      () -> assertEquals("a", remSeqChars("a")),
      () -> assertEquals("", remSeqChars("")));
  }
}
\end{lstlisting}

\begin{lstlisting}[language=MyJava]
class RemoveSequentialChars {

  /**
   * Removes sequential characters from a string.
   * @param s the given string.
   * @return the resulting string.
   */
  static String remSeqChars(String s) {
    return remSeqCharsHelper(s, '\0');
  }

  /**
   * Helper method to remove sequential characters from a string.
   * @param s the given string.
   * @param c the character to remove from the string.
   * @return the resulting string.
   */
  private static String remSeqCharsHelper(String s, char c) {
    if (s.isEmpty()) {
      return "";
    } else if (s.charAt(0) != c) {
      return s.charAt(0) + remSeqCharsHelper(s.substring(1), s.charAt(0));
    } else {
      return remSeqCharsHelper(s.substring(1), c);
    }
  }
}
\end{lstlisting}

\begin{lstlisting}[language=MyJava]
class RemoveSequentialChars {

  /**
   * Tail recursive (driver) method to remove sequential characters from a string.
   * @param s the given string.
   * @return the resulting string.
   */
  static String remSeqCharsTR(String s) {
    return remSeqCharsTRHelper(s, '\0', "");
  }

  /**
   * Tail recursive helper method for remSeqCharsTR.
   * @param s the given string.
   * @param c the character to remove from the string.
   * @param acc the accumulator for the result.
   * @return the resulting string.
   */
  private static String remSeqCharsHelper(String s, char c, String acc) {
    if (s.isEmpty()) {
      return acc;
    } else if (s.charAt(0) != c) {
      return remSeqCharsHelper(s.substring(1), s.charAt(0), acc + s.charAt(0));
    } else {
      return remSeqCharsHelper(s.substring(1), c, acc);
    }
  }
}
\end{lstlisting}

\myexample{Exponentiation is an incredibly common mathematical operation that, like factorial, may be represented as a recurrence relation.}
That is, $n^b$ where $n > 0$ and $b \geq 0$ is defined as $n \cdot n^{b-1}$ for~$b > 0$, and~$1$ when~$b=0$.
The simple algorithm is to naturally recurse on~$b$ until it is zero. 
Because we know that $b$ is a natural number, we can design a substantially faster algorithm.
Recall the rules of exponents, namely that $n^{2b} = (n^b)^2$. 
Using this equivalence, when the exponent is even, we square the result and divide the given exponent in half.
If it is odd, we recurse with one less than the exponent.

The standard recursive \ttt{pow} method receives two arguments:~$n$ and~$b$, and recurses over~$b$ until it is zero.
On the other hand, the tail recursive counterpart accumulates the result as a parameter.
In either method, we must handle a case analysis on the parity of~$b$, i.e., determine whether~$b$ is even or odd.
Both method implementations utilize the same test cases, and we will show both testing suites.

\begin{lstlisting}[language=MyJava]
import static Assertions.assertAll;
import static Assertions.assertEquals;

class PowTester {

  @Test
  void testPow() {
    assertAll(
      () -> assertEquals(1, pow(42, 0)),
      () -> assertEquals(81, pow(9, 2)),
      () -> assertEquals(16777216, pow(4, 12)));
  }

  @Test
  void testPowTR() {
    assertAll(
      () -> assertEquals(1, powTR(42, 0)),
      () -> assertEquals(81, powTR(9, 2)),
      () -> assertEquals(16777216, powTR(4, 12)));
  }
}
\end{lstlisting}

\begin{lstlisting}[language=MyJava]
class Pow {

  /**
   * Calculates the result of raising a base number to an exponent.
   * The method uses standard recursion over ints, so make sure that
   * neither parameter are very large!
   * @param n the base number.
   * @param b the exponent.
   * @return the result of n raised to the power of b.
   */
  static int pow(int n, int b) {
    if (b == 0) {
      return 1;
    } else if (b % 2 == 0) {
      return n * n * pow(n, b / 2);
    } else {
      return n * pow(n, b - 1);
    }
  }
}
\end{lstlisting}

\begin{lstlisting}[language=MyJava]
class Pow {

  /**
   * Calculates the result of raising a base number to an exponent.
   * The helper method uses tail recursion over ints, so make sure that
   * neither parameter are very large!
   * @param n the base number.
   * @param b the exponent.
   * @return the result of n raised to the power of b.
   */
  static int powTR(int n, int b) {
    return powTR(n, b, 1);
  }

  /**
   * Tail recursive helper method for powTR.
   * @param n the base number.
   * @param b the exponent.
   * @param acc the intermediary result of n^b.
   * @return acc.
   */
  private static int powTRHelper(int n, int b, int acc) {
    if (b == 0) { 
      return acc; 
    } else if (b % 2 == 0) {
      return powTRHelper(n, b / 2, n * n * acc);
    } else {
      return powTRHelper(n, b - 1, n * acc);
    }
  }
}
\end{lstlisting}

\myexample{Let's design a method to count the number of digits in a positive integer.}
It's important to realize that we can write an algorithm to compute such a value using only mathematical operations, i.e., exponents and logarithms.
% We will employ a recursive algorithm to further demonstrate the power of recursion.
Let's first design the standard recursive algorithm and then write the tail recursive variant.
The standard recursive algorithm has a base case, namely when its input is less than~$10$. If so, we know the number has only one digit and can return accordingly.
We recurse on the number after removing a digit.
Digits are removed by dividing the input by ten.
The tail recursive algorithm delegates the return value to an accumulator.
By designing the tests for one of the algorithms, we inadvertently write tests for the other!

\enlargethispage{-2\baselineskip}
\begin{lstlisting}[language=MyJava]
import static Assertions.assertAll;
import static Assertions.assertEquals;

class CountDigitTester {

  @Test
  void testCountDigit() {
    assertAll(
      () -> assertEquals(1, countDigits(0)),
      () -> assertEquals(3, countDigits(123)),
      () -> assertEquals(4, countDigits(5192)));
  }

  @Test
  void testCountDigitTR() {
    assertAll(
      () -> assertEquals(1, countDigitsTR(0)),
      () -> assertEquals(3, countDigitsTR(123)),
      () -> assertEquals(4, countDigitsTR(5192)));
  }
}
\end{lstlisting}

\begin{lstlisting}[language=MyJava]
class CountDigit {

  /**
   * Counts the number of digits in a positive integer.
   * @param n positive integer.
   * @return number of digits.
   */
  static int countDigits(int n) {
    if (n < 10) {
      return 1;
    } else {
      return 1 + countDigits(n / 10);
    }
  }
}
\end{lstlisting}

\begin{lstlisting}[language=MyJava]
class CountDigit {

  /**
   * Counts the number of digits in a positive integer
   * using tail recursion.
   * @param n positive integer.
   * @return number of digits.
   */
  static int countDigitsTR(int n) {
    return countDigitsTRHelper(n, 1);
  }

  /**
   * Helper method for computing the number of digits.
   * @param n positive integer.
   * @param acc accumulator for # of digits.
   * @return number of digits.
   */
  private static int countDigitsTRHelper(int n, int acc) {
    if (n < 10) {
      return acc;
    } else {
      return countDigitsTRHelper(n / 10, acc + 1);
    }
  }
}
\end{lstlisting}

So, we have explored both standard and tail recursive methods, and how a programming language might optimize tail recursive calls. 
The thing is, tail recursion has a direct correspondence to loops, i.e., \ttt{while}. 
In fact, some programming languages convert all tail recursive functions into their iterative counterparts, alleviating the need for a stack whatsoever.
Replacing tail recursion, or tail recursive calls, with iteration is known as \emph{tail call optimization}\index{tail call optimization}.
As we stated, Java is not a language that supports tail call optimization out of respect for maintaining the call stack when debugging.
Moreover, Java allows the programmer to investigate the call stack explicitly in their program.
Employing tail call optimization would break existing programs that rely on the ability to walk through stack frames.
The fact that Java does not perform tail call optimization means that tail calls continue to blow up the call stack.
In the next section, we will discuss a translation pipeline from tail recursion to loops in greater detail, as well as describe the syntax and semantics of Java iteration structures.

% \begin{enumerate}
%   \item \mcq{What is a recursive method in Java?}{A method that calls other methods exclusively,A method that never returns,A method that calls itself within its own body,A method that can only be called once}
  
%   \item \mcq{Why is recursion used in programming?}{To make the code run faster,To reduce the memory usage of the program,To solve a large problem by breaking it down into smaller problems,To increase the complexity of the code}
  
%   \item \mcq{What is the base case in a recursive method?}{The most complex case to solve,The initial value from which recursion starts,The condition under which the method stops calling itself,The final step that combines all results}
  
%   \item \mcq{What is tail recursion?}{A special form of recursion where the recursive call is the last operation in the method,Recursion that does not use any stack memory,Recursion that can only be used with tail data structures,Recursion where the method only calls itself once}
  
%   \item \mcq{Why is tail recursion preferred over standard recursion in some cases?}{Because it is easier to understand,Because it can be optimized by the compiler to use less stack memory,Because it allows recursion to be used in more scenarios,Because it is faster in all cases}
  
%   \item \mcq{What role does an accumulator play in tail recursion?}{It stores intermediate results and helps avoid stack overflow,It counts the number of recursive calls,It determines when the recursion should stop,It optimizes the recursion to run faster}
  
%   \item \mcq{How can tail recursion typically be replaced in programming?}{With a \texttt{switch} statement,With a \texttt{for} loop,With a \texttt{while} loop or \texttt{for} loop,With an \texttt{if-else} structure}

%   \item \mcq{What is the purpose of a driver method in the context of recursion?}{To initiate the recursive process with the correct initial values,To drive the program to use more stack memory,To convert recursion into iteration,To drive the recursion faster towards the base case}
% \end{enumerate}
